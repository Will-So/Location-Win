{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the Number Of Passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your corpus is very large, then one pass would be enough. Passes is the number of training passes through the corpus. \n",
    "\n",
    "The number of updates is `n_passes * documents / chunk_size`\n",
    "\n",
    "In the distributed version, `update_every` is every worker. It is done on the per pass/chunk size. Neglecting this fact can lead to not updating the topics enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A word on Hyperparamters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't recommend changing hyperparamter priors unless you have good reason to do so. Note that decay is kappa and 0.5 is the best according to Hoffman (2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the Beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Good Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess by removing stopwords and most punctuation. Also tokenize and make lower case. \n",
    "2. Consider using a POS tagger for \n",
    "3. Use wordnet \n",
    "\n",
    "    ```python\n",
    "    tokens = [x[0] for x in nltk.pos_tag(tokens) if x[1] in \n",
    "                    ('NN', 'JJ') and x[0] not in name_tokens and len(x[0]) > 2 and\n",
    "                    wordnet.sysnet(term)\n",
    "```\n",
    "\n",
    "4. Apply tfidf\n",
    "5. Use LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways to use LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exploratory Analysis. Using `pyLDAviz` to visualize the topics can be especially interesting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [cool vis](http://nbviewer.ipython.org/github/bmabey/pyLDAvis/blob/master/notebooks/Gensim%20Newsgroup.ipynb#topic=5&lambda=0.58&term=) and [another](http://nbviewer.ipython.org/github/bmabey/hacker_news_topic_modelling/blob/master/HN%20Topic%20Model%20Talk.ipynb#topic=2&lambda=1&term=)\n",
    "- [Beer Presentation](https://speakerdeck.com/bfields/great-taste-less-wordy-document-summarization-of-beer-reviews)\n",
    "- Hoffman, Matthew, Francis R. Bach, and David M. Blei. \"Online learning for latent dirichlet allocation.\" advances in neural information processing systems. 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}